{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsQCTvQW4sQaPQULz8zSvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramalamadingdong/yolo-rb3gen2-trainer/blob/main/Demo_YOLO_to_RB3Gen2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Retrain YOLOv8 on Synthetic Data\n",
        "\n",
        "\n",
        "Make sure you're connected to a T4 Google compute engine"
      ],
      "metadata": {
        "id": "XGnEFcOLqF7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fjoMWTqBpPui",
        "outputId": "04ffbfe0-6fbd-425d-b88d-080580fb0e69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolo-rb3gen2-trainer'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 36 (delta 10), reused 17 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 142.16 KiB | 5.47 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "/content/yolo-rb3gen2-trainer\n",
            "Collecting ultralytics (from -r requirements.txt (line 1))\n",
            "  Downloading ultralytics-8.3.111-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.6.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.3.56 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (4.11.0.86)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 1))\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 8)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->-r requirements.txt (line 10)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->-r requirements.txt (line 10)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->-r requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->-r requirements.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.2->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 2)) (3.0.2)\n",
            "Downloading ultralytics-8.3.111-py3-none-any.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.8/978.8 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.111 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ramalamadingdong/yolo-rb3gen2-trainer\n",
        "%cd yolo-rb3gen2-trainer\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "8qAfKMBNq_Ao",
        "collapsed": true,
        "outputId": "05f392ca-639e-4250-d944-00ca2260836f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The following functions are used to prepare data.\n",
        "\n",
        "def create_directories(output_dir):\n",
        "    \"\"\"Create necessary output directories.\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    train_dir = output_dir / 'train'\n",
        "    val_dir = output_dir / 'val'\n",
        "    for split in [train_dir, val_dir]:\n",
        "        (split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "        (split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "    return output_dir, train_dir, val_dir\n",
        "\n",
        "def add_training_picture(draw, image_size):\n",
        "    \"\"\"Place an training image with random position and rotation.\"\"\"\n",
        "\n",
        "    train_img_pth = random.choice(list(Path('/content/yolo-rb3gen2-trainer/training_images').glob('*.png')))\n",
        "    tag = Image.open(train_img_pth).convert('L')  # Convert to grayscale for better quality\n",
        "\n",
        "    # YOU MAY WANT TO CHANGE THIS FOR BETTER RESULTS\n",
        "    # Randomly resize tag between 40-120 pixels while maintaining aspect ratio\n",
        "    tag_w, tag_h = tag.size\n",
        "    target_size = random.randint(40, 120)\n",
        "    scale = min(target_size/tag_w, target_size/tag_h)\n",
        "    new_size = (int(tag_w * scale), int(tag_h * scale))\n",
        "\n",
        "    # Use nearest neighbor resampling to preserve sharp edges and binary nature of Training picture\n",
        "    tag = tag.resize(new_size, Image.NEAREST)\n",
        "\n",
        "    # Threshold to ensure pure black and white\n",
        "    tag = tag.point(lambda x: 0 if x < 128 else 255, '1')\n",
        "\n",
        "    # Get new dimensions after resize\n",
        "    width, height = tag.size\n",
        "\n",
        "    # Random position\n",
        "    x = random.randint(0, image_size[0] - width)\n",
        "    y = random.randint(0, image_size[1] - height)\n",
        "\n",
        "    # Random rotation angle\n",
        "    angle = random.uniform(0, 360)\n",
        "\n",
        "    # Apply rotation\n",
        "    tag = tag.rotate(angle, expand=False)\n",
        "\n",
        "    # Get rotated dimensions\n",
        "    rot_width, rot_height = tag.size\n",
        "\n",
        "    # Paste rotated tag onto image\n",
        "    draw._image.paste(tag, (x - (rot_width - width)//2, y - (rot_height - height)//2))\n",
        "\n",
        "    # Calculate corners of rotated rectangle\n",
        "    center_x = x + width/2\n",
        "    center_y = y + height/2\n",
        "\n",
        "    # Return corners for bounding box calculation\n",
        "    corners = [\n",
        "        (x, y),\n",
        "        (x + rot_width, y),\n",
        "        (x + rot_width, y + rot_height),\n",
        "        (x, y + rot_height)\n",
        "    ]\n",
        "    return corners\n",
        "\n",
        "def create_yolo_label(shape, class_id, image_size):\n",
        "    \"\"\"Convert shape coordinates to YOLO format.\"\"\"\n",
        "    x_coords = [p[0] for p in shape]\n",
        "    y_coords = [p[1] for p in shape]\n",
        "    x_center = (min(x_coords) + max(x_coords)) / (2 * image_size[0])\n",
        "    y_center = (min(y_coords) + max(y_coords)) / (2 * image_size[1])\n",
        "    width = (max(x_coords) - min(x_coords)) / image_size[0]\n",
        "    height = (max(y_coords) - min(y_coords)) / image_size[1]\n",
        "\n",
        "    return f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "def generate_dataset(output_dir, num_images, image_size):\n",
        "    \"\"\"Generate synthetic dataset with images and labels.\"\"\"\n",
        "    output_dir, train_dir, val_dir = create_directories(output_dir)\n",
        "    classes = ['AprilTag']\n",
        "\n",
        "    # Split into train and validation\n",
        "    train_size = int(0.8 * num_images)\n",
        "    val_size = num_images - train_size\n",
        "\n",
        "    for split, size in [('train', train_size), ('val', val_size)]:\n",
        "        print(f\"Generating {split} dataset...\")\n",
        "        for i in range(size):\n",
        "            # Load base image\n",
        "            image = Image.open('/content/yolo-rb3gen2-trainer/base_image.jpg').resize(image_size)\n",
        "            draw = ImageDraw.Draw(image)\n",
        "\n",
        "            # Generate random number of shapes\n",
        "            num_shapes = random.randint(1, 3)\n",
        "            labels = []\n",
        "\n",
        "            for _ in range(num_shapes):\n",
        "                skewed_corners = add_training_picture(draw, image_size)\n",
        "\n",
        "                # Calculate bounding box from skewed corners with padding\n",
        "                x_coords = [corner[0] for corner in skewed_corners]\n",
        "                y_coords = [corner[1] for corner in skewed_corners]\n",
        "\n",
        "                # Add 20% padding to bounding box\n",
        "                padding_x = (max(x_coords) - min(x_coords)) * 0.1\n",
        "                padding_y = (max(y_coords) - min(y_coords)) * 0.1\n",
        "\n",
        "                bbox = [\n",
        "                    (max(0, min(x_coords) - padding_x), max(0, min(y_coords) - padding_y)),\n",
        "                    (min(image_size[0], max(x_coords) + padding_x),\n",
        "                     min(image_size[1], max(y_coords) + padding_y))\n",
        "                ]\n",
        "\n",
        "                label = create_yolo_label(bbox, classes.index(\"AprilTag\"), image_size)\n",
        "                labels.append(label)\n",
        "\n",
        "            # Save image\n",
        "            image_path = output_dir / split / 'images' / f'image_{i:04d}.jpg'\n",
        "            image.save(image_path)\n",
        "\n",
        "            # Save label\n",
        "            label_path = output_dir / split / 'labels' / f'image_{i:04d}.txt'\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write('\\n'.join(labels))\n",
        "\n",
        "def create_dataset_yaml(output_dir):\n",
        "    \"\"\"Create YAML file for dataset configuration.\"\"\"\n",
        "    classes = ['AprilTag']\n",
        "    yaml_content = {\n",
        "        'path': str(output_dir),\n",
        "        'train': '/content/yolo-rb3gen2-trainer/data/train/images',\n",
        "        'val': '/content/yolo-rb3gen2-trainer/data/val/images',\n",
        "        'nc': len(classes),\n",
        "        'names': classes\n",
        "    }\n",
        "\n",
        "    with open(output_dir / 'dataset.yaml', 'w') as f:\n",
        "        yaml.dump(yaml_content, f, sort_keys=False)"
      ],
      "metadata": {
        "id": "7Nw3iab5rfr-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The following functions are used to Train Yolo.\n",
        "\n",
        "def load_config(config_path: str = \"/content/yolo-rb3gen2-trainer/config.yaml\"):\n",
        "    \"\"\"\n",
        "    Load configuration from YAML file.\n",
        "\n",
        "    Args:\n",
        "        config_path (str): Path to the config.yaml file\n",
        "\n",
        "    Returns:\n",
        "        dict: Configuration dictionary\n",
        "    \"\"\"\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    return config\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory and garbage collection\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def train_yolo(\n",
        "    data_yaml_path: str,\n",
        "    config_path: str = \"/content/yolo-rb3gen2-trainer/config.yaml\",\n",
        "    **kwargs\n",
        "):\n",
        "    \"\"\"\n",
        "    Train a YOLOv8 model on a custom dataset using configurations from config.yaml.\n",
        "\n",
        "    Args:\n",
        "        data_yaml_path (str): Path to the data.yaml file containing dataset configuration\n",
        "        config_path (str): Path to the config.yaml file containing training configuration\n",
        "        **kwargs: Additional arguments to override config settings\n",
        "    \"\"\"\n",
        "    # Clear GPU memory before starting\n",
        "    clear_gpu_memory()\n",
        "\n",
        "    # Load configuration\n",
        "    config = load_config(config_path)\n",
        "\n",
        "    # Get model configuration\n",
        "    model_config = config['model']\n",
        "    model_type = f\"{model_config['type']}.pt\"\n",
        "\n",
        "    # Get training configuration\n",
        "    train_config = config['train']\n",
        "\n",
        "    # Update training config with any provided kwargs\n",
        "    train_config.update(kwargs)\n",
        "\n",
        "    # Initialize model\n",
        "    model = YOLO(model_type)\n",
        "\n",
        "    # Train the model with error handling\n",
        "    try:\n",
        "        results = model.train(\n",
        "            data=data_yaml_path,\n",
        "            epochs=train_config['epochs'],\n",
        "            batch=train_config['batch_size'],\n",
        "            imgsz=train_config['imgsz'],\n",
        "            device=train_config['device'],\n",
        "            project=train_config['project'],\n",
        "            name=train_config['name'],\n",
        "            exist_ok=train_config['exist_ok'],\n",
        "            pretrained=train_config['pretrained'],\n",
        "            optimizer=train_config['optimizer'],\n",
        "            verbose=train_config['verbose'],\n",
        "            seed=train_config['seed'],\n",
        "            deterministic=train_config['deterministic'],\n",
        "            single_cls=train_config['single_cls'],\n",
        "            rect=train_config['rect'],\n",
        "            cos_lr=train_config['cos_lr'],\n",
        "            close_mosaic=train_config['close_mosaic'],\n",
        "            resume=train_config['resume'],\n",
        "            amp=train_config['amp'],\n",
        "            fraction=train_config['fraction'],\n",
        "            nbs=train_config['nbs'],\n",
        "            overlap_mask=train_config['overlap_mask'],\n",
        "            mask_ratio=train_config['mask_ratio'],\n",
        "            dropout=train_config['dropout'],\n",
        "            val=train_config['val']\n",
        "        )\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training error occurred: {str(e)}\")\n",
        "        # Clear GPU memory after error\n",
        "        clear_gpu_memory()\n",
        "        raise e"
      ],
      "metadata": {
        "id": "nljhNibtr5V0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "output_dir = 'data'\n",
        "num_images = 100\n",
        "image_size = (1280, 720)\n",
        "\n",
        "# Generate dataset\n",
        "generate_dataset(output_dir, num_images, image_size)\n",
        "\n",
        "# Create dataset YAML\n",
        "create_dataset_yaml(Path(output_dir))\n",
        "\n",
        "print(\"Dataset generation completed!\")"
      ],
      "metadata": {
        "id": "xLSuA8jLsRAv",
        "outputId": "f2a6f3ec-de88-43ee-adb5-28ea544a54e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating train dataset...\n",
            "Generating val dataset...\n",
            "Dataset generation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your data.yaml file\n",
        "data_yaml = \"/content/yolo-rb3gen2-trainer/data/dataset.yaml\"\n",
        "# Train the model using configurations from config.yaml\n",
        "results = train_yolo(\n",
        "    data_yaml_path=str(data_yaml)\n",
        ")"
      ],
      "metadata": {
        "id": "Gita_NEEsmuE",
        "outputId": "343282ea-5270-460a-9e08-6e0155cb8256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA device: Tesla T4\n",
            "CUDA version: 12.4\n",
            "PyTorch version: 2.6.0+cu124\n",
            "Available GPU memory: 14.74 GB\n",
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/yolo-rb3gen2-trainer/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/yolo-rb3gen2-trainer/data/dataset.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=runs/train, name=exp, exist_ok=True, pretrained=True, optimizer=SGD, verbose=True, seed=42, deterministic=True, single_cls=False, rect=True, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=16, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/train/exp\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 40.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 118MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1470.5±379.9 MB/s, size: 59.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo-rb3gen2-trainer/data/train/labels... 80 images, 0 backgrounds, 0 corrupt: 100%|██████████| 80/80 [00:00<00:00, 2167.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo-rb3gen2-trainer/data/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "WARNING ⚠️ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 672.3±395.7 MB/s, size: 59.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo-rb3gen2-trainer/data/val/labels... 20 images, 0 backgrounds, 0 corrupt: 100%|██████████| 20/20 [00:00<00:00, 1194.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo-rb3gen2-trainer/data/val/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      1.24G      1.368      3.563      1.088         36        640: 100%|██████████| 5/5 [00:02<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         20         38    0.00517      0.816    0.00886    0.00522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "      2/100      1.31G      1.189      3.403       1.04         37        640: 100%|██████████| 5/5 [00:00<00:00,  5.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         20         38    0.00533      0.842     0.0126    0.00956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      1.32G     0.7969       2.85     0.8894         36        640: 100%|██████████| 5/5 [00:00<00:00,  5.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         20         38    0.00617      0.974     0.0213     0.0186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "      4/100      1.33G     0.6568       1.41     0.8321         36        640: 100%|██████████| 5/5 [00:00<00:00,  5.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display training results\n",
        "print(\"Training completed!\")\n",
        "print(f\"Results saved to: {results.save_dir}\")"
      ],
      "metadata": {
        "id": "LBUoMQuGspFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps: Preperation / Quantization of the model for RB3Gen2\n",
        "I recommend the following be run on your personal machine but you can do this on the Colab too however the last step takes forever to complete."
      ],
      "metadata": {
        "id": "wRNV4mdSoXhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qai-hub-models[yolov8-det-quantized]"
      ],
      "metadata": {
        "id": "j7o6xmuDkyIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Account on AI Hub and get API Token.\n",
        "!qai-hub configure --api_token <YOUR_API_TOKEN>"
      ],
      "metadata": {
        "id": "0qe0HijnlFEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m qai_hub_models.models.yolov8_det_quantized.export --device=\"RB3 Gen 2 (Proxy)\" --ckpt-name /content/runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "clJsd7QymJj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RB3Gen2 Preperation / RB3Gen2 Commands\n"
      ],
      "metadata": {
        "id": "0VAykKdar521"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"PATH_TO_FILE_FROM_AIHUB\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get output tensor details\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "q_scales = []\n",
        "q_zero_points = []\n",
        "\n",
        "for output in output_details:\n",
        "    params = output['quantization_parameters']\n",
        "\n",
        "    # Check if the tensor is quantized\n",
        "    if output['quantization_parameters']['quantized_dimension'] == 0:  # Per-tensor quantization\n",
        "        scale = params['scales'][0] if params['scales'].size > 0 else 1.0\n",
        "        zero_point = params['zero_points'][0] if params['zero_points'].size > 0 else 0.0\n",
        "    else:\n",
        "        # Handle per-channel quantization (unlikely for YOLOv8)\n",
        "        scale = 1.0\n",
        "        zero_point = 0.0\n",
        "\n",
        "    q_scales.append(scale)\n",
        "    q_zero_points.append(float(zero_point))\n",
        "\n",
        "# Format the constants\n",
        "print(f'YOLOv8,q-offsets=<{\", \".join(map(str, q_zero_points))}>, q-scales=<{\", \".join(map(str, q_scales))}>')"
      ],
      "metadata": {
        "id": "P80_o_Q4slaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gst-launch-1.0 -e --gst-debug=2 \\\n",
        "qtiqmmfsrc name=camsrc ! video/x-raw\\(memory:GBM\\),format=NV12,width=1280,height=720,framerate=30/1,compression=ubwc ! queue ! tee name=split \\\n",
        "split. ! queue ! qtivcomposer name=mixer ! queue ! waylandsink fullscreen=true \\\n",
        "split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so \\\n",
        "external-delegate-options=\"QNNExternalDelegate,backend_type=htp;\" model=/opt/yolov8_det_quantized.tflite ! queue ! \\\n",
        "qtimlvdetection threshold=50.0 results=10 module=yolov8 labels=/opt/coco_labels.txt constants=\"YOLOv8,q-offsets=<21.0, 0.0, 0.0>,q-scales=<3.093529462814331, 0.00390625, 1.0>;\" ! \\\n",
        "video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.\n"
      ],
      "metadata": {
        "id": "wzc7bZxss4tC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}