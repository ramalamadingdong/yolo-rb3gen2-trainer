{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQwYDBNUixUv4m6X1/Rph8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramalamadingdong/yolo-rb3gen2-trainer/blob/main/Demo_YOLO_to_RB3Gen2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Retrain YOLOv8 on Synthetic Data"
      ],
      "metadata": {
        "id": "XGnEFcOLqF7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjoMWTqBpPui"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ramalamadingdong/yolo-rb3gen2-trainer\n",
        "%cd yolo-rb3gen2-trainer\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "8qAfKMBNq_Ao",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The following functions are used to prepare data.\n",
        "\n",
        "def create_directories(output_dir):\n",
        "    \"\"\"Create necessary output directories.\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    train_dir = output_dir / 'train'\n",
        "    val_dir = output_dir / 'val'\n",
        "    for split in [train_dir, val_dir]:\n",
        "        (split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "        (split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "    return output_dir, train_dir, val_dir\n",
        "\n",
        "def add_training_picture(draw, image_size):\n",
        "    \"\"\"Place an training image with random position and rotation.\"\"\"\n",
        "\n",
        "    train_img_pth = random.choice(list(Path('/content/yolo-rb3gen2-trainer/training_images').glob('*.png')))\n",
        "    tag = Image.open(train_img_pth).convert('L')  # Convert to grayscale for better quality\n",
        "\n",
        "    # YOU MAY WANT TO CHANGE THIS FOR BETTER RESULTS\n",
        "    # Randomly resize tag between 40-120 pixels while maintaining aspect ratio\n",
        "    tag_w, tag_h = tag.size\n",
        "    target_size = random.randint(40, 120)\n",
        "    scale = min(target_size/tag_w, target_size/tag_h)\n",
        "    new_size = (int(tag_w * scale), int(tag_h * scale))\n",
        "\n",
        "    # Use nearest neighbor resampling to preserve sharp edges and binary nature of Training picture\n",
        "    tag = tag.resize(new_size, Image.NEAREST)\n",
        "\n",
        "    # Threshold to ensure pure black and white\n",
        "    tag = tag.point(lambda x: 0 if x < 128 else 255, '1')\n",
        "\n",
        "    # Get new dimensions after resize\n",
        "    width, height = tag.size\n",
        "\n",
        "    # Random position\n",
        "    x = random.randint(0, image_size[0] - width)\n",
        "    y = random.randint(0, image_size[1] - height)\n",
        "\n",
        "    # Random rotation angle\n",
        "    angle = random.uniform(0, 360)\n",
        "\n",
        "    # Apply rotation\n",
        "    tag = tag.rotate(angle, expand=False)\n",
        "\n",
        "    # Get rotated dimensions\n",
        "    rot_width, rot_height = tag.size\n",
        "\n",
        "    # Paste rotated tag onto image\n",
        "    draw._image.paste(tag, (x - (rot_width - width)//2, y - (rot_height - height)//2))\n",
        "\n",
        "    # Calculate corners of rotated rectangle\n",
        "    center_x = x + width/2\n",
        "    center_y = y + height/2\n",
        "\n",
        "    # Return corners for bounding box calculation\n",
        "    corners = [\n",
        "        (x, y),\n",
        "        (x + rot_width, y),\n",
        "        (x + rot_width, y + rot_height),\n",
        "        (x, y + rot_height)\n",
        "    ]\n",
        "    return corners\n",
        "\n",
        "def create_yolo_label(shape, class_id, image_size):\n",
        "    \"\"\"Convert shape coordinates to YOLO format.\"\"\"\n",
        "    x_coords = [p[0] for p in shape]\n",
        "    y_coords = [p[1] for p in shape]\n",
        "    x_center = (min(x_coords) + max(x_coords)) / (2 * image_size[0])\n",
        "    y_center = (min(y_coords) + max(y_coords)) / (2 * image_size[1])\n",
        "    width = (max(x_coords) - min(x_coords)) / image_size[0]\n",
        "    height = (max(y_coords) - min(y_coords)) / image_size[1]\n",
        "\n",
        "    return f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "def generate_dataset(output_dir, num_images, image_size):\n",
        "    \"\"\"Generate synthetic dataset with images and labels.\"\"\"\n",
        "    output_dir, train_dir, val_dir = create_directories(output_dir)\n",
        "    classes = ['AprilTag']\n",
        "\n",
        "    # Split into train and validation\n",
        "    train_size = int(0.8 * num_images)\n",
        "    val_size = num_images - train_size\n",
        "\n",
        "    for split, size in [('train', train_size), ('val', val_size)]:\n",
        "        print(f\"Generating {split} dataset...\")\n",
        "        for i in range(size):\n",
        "            # Load base image\n",
        "            image = Image.open('/content/yolo-rb3gen2-trainer/base_image.jpg').resize(image_size)\n",
        "            draw = ImageDraw.Draw(image)\n",
        "\n",
        "            # Generate random number of shapes\n",
        "            num_shapes = random.randint(1, 3)\n",
        "            labels = []\n",
        "\n",
        "            for _ in range(num_shapes):\n",
        "                skewed_corners = add_training_picture(draw, image_size)\n",
        "\n",
        "                # Calculate bounding box from skewed corners with padding\n",
        "                x_coords = [corner[0] for corner in skewed_corners]\n",
        "                y_coords = [corner[1] for corner in skewed_corners]\n",
        "\n",
        "                # Add 20% padding to bounding box\n",
        "                padding_x = (max(x_coords) - min(x_coords)) * 0.1\n",
        "                padding_y = (max(y_coords) - min(y_coords)) * 0.1\n",
        "\n",
        "                bbox = [\n",
        "                    (max(0, min(x_coords) - padding_x), max(0, min(y_coords) - padding_y)),\n",
        "                    (min(image_size[0], max(x_coords) + padding_x),\n",
        "                     min(image_size[1], max(y_coords) + padding_y))\n",
        "                ]\n",
        "\n",
        "                label = create_yolo_label(bbox, classes.index(\"AprilTag\"), image_size)\n",
        "                labels.append(label)\n",
        "\n",
        "            # Save image\n",
        "            image_path = output_dir / split / 'images' / f'image_{i:04d}.jpg'\n",
        "            image.save(image_path)\n",
        "\n",
        "            # Save label\n",
        "            label_path = output_dir / split / 'labels' / f'image_{i:04d}.txt'\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write('\\n'.join(labels))\n",
        "\n",
        "def create_dataset_yaml(output_dir):\n",
        "    \"\"\"Create YAML file for dataset configuration.\"\"\"\n",
        "    classes = ['AprilTag']\n",
        "    yaml_content = {\n",
        "        'path': str(output_dir),\n",
        "        'train': '/content/data/train/images',\n",
        "        'val': '/content/data/val/images',\n",
        "        'nc': len(classes),\n",
        "        'names': classes\n",
        "    }\n",
        "\n",
        "    with open(output_dir / 'dataset.yaml', 'w') as f:\n",
        "        yaml.dump(yaml_content, f, sort_keys=False)"
      ],
      "metadata": {
        "id": "7Nw3iab5rfr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The following functions are used to Train Yolo.\n",
        "\n",
        "def load_config(config_path: str = \"/content/yolo-rb3gen2-trainer/config.yaml\"):\n",
        "    \"\"\"\n",
        "    Load configuration from YAML file.\n",
        "\n",
        "    Args:\n",
        "        config_path (str): Path to the config.yaml file\n",
        "\n",
        "    Returns:\n",
        "        dict: Configuration dictionary\n",
        "    \"\"\"\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    return config\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory and garbage collection\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def train_yolo(\n",
        "    data_yaml_path: str,\n",
        "    config_path: str = \"/content/yolo-rb3gen2-trainer/config.yaml\",\n",
        "    **kwargs\n",
        "):\n",
        "    \"\"\"\n",
        "    Train a YOLOv8 model on a custom dataset using configurations from config.yaml.\n",
        "\n",
        "    Args:\n",
        "        data_yaml_path (str): Path to the data.yaml file containing dataset configuration\n",
        "        config_path (str): Path to the config.yaml file containing training configuration\n",
        "        **kwargs: Additional arguments to override config settings\n",
        "    \"\"\"\n",
        "    # Clear GPU memory before starting\n",
        "    clear_gpu_memory()\n",
        "\n",
        "    # Load configuration\n",
        "    config = load_config(config_path)\n",
        "\n",
        "    # Get model configuration\n",
        "    model_config = config['model']\n",
        "    model_type = f\"{model_config['type']}.pt\"\n",
        "\n",
        "    # Get training configuration\n",
        "    train_config = config['train']\n",
        "\n",
        "    # Update training config with any provided kwargs\n",
        "    train_config.update(kwargs)\n",
        "\n",
        "    # Force CPU device if CUDA is causing issues\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            # Print CUDA device information\n",
        "            print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "            print(f\"CUDA version: {torch.version.cuda}\")\n",
        "            print(f\"PyTorch version: {torch.__version__}\")\n",
        "            print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "            # Test CUDA compatibility with smaller batch size\n",
        "            test_model = YOLO(model_type)\n",
        "            test_model.to('cuda')\n",
        "            test_model.predict('https://ultralytics.com/images/bus.jpg', device='cuda', batch=1)\n",
        "\n",
        "            # Clear memory after test\n",
        "            clear_gpu_memory()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"CUDA compatibility issue detected: {str(e)}\")\n",
        "            print(\"Falling back to CPU.\")\n",
        "            train_config['device'] = 'cpu'\n",
        "    else:\n",
        "        print(\"CUDA is not available. Using CPU.\")\n",
        "        train_config['device'] = 'cpu'\n",
        "\n",
        "    # Initialize model\n",
        "    model = YOLO(model_type)\n",
        "\n",
        "    # Train the model with error handling\n",
        "    try:\n",
        "        results = model.train(\n",
        "            data=data_yaml_path,\n",
        "            epochs=train_config['epochs'],\n",
        "            batch=train_config['batch_size'],\n",
        "            imgsz=train_config['imgsz'],\n",
        "            device=train_config['device'],\n",
        "            project=train_config['project'],\n",
        "            name=train_config['name'],\n",
        "            exist_ok=train_config['exist_ok'],\n",
        "            pretrained=train_config['pretrained'],\n",
        "            optimizer=train_config['optimizer'],\n",
        "            verbose=train_config['verbose'],\n",
        "            seed=train_config['seed'],\n",
        "            deterministic=train_config['deterministic'],\n",
        "            single_cls=train_config['single_cls'],\n",
        "            rect=train_config['rect'],\n",
        "            cos_lr=train_config['cos_lr'],\n",
        "            close_mosaic=train_config['close_mosaic'],\n",
        "            resume=train_config['resume'],\n",
        "            amp=train_config['amp'],\n",
        "            fraction=train_config['fraction'],\n",
        "            nbs=train_config['nbs'],\n",
        "            overlap_mask=train_config['overlap_mask'],\n",
        "            mask_ratio=train_config['mask_ratio'],\n",
        "            dropout=train_config['dropout'],\n",
        "            val=train_config['val']\n",
        "        )\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training error occurred: {str(e)}\")\n",
        "        # Clear GPU memory after error\n",
        "        clear_gpu_memory()\n",
        "        raise e"
      ],
      "metadata": {
        "id": "nljhNibtr5V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "output_dir = 'data'\n",
        "num_images = 100\n",
        "image_size = (1280, 720)\n",
        "\n",
        "# Generate dataset\n",
        "generate_dataset(output_dir, num_images, image_size)\n",
        "\n",
        "# Create dataset YAML\n",
        "create_dataset_yaml(Path(output_dir))\n",
        "\n",
        "print(\"Dataset generation completed!\")"
      ],
      "metadata": {
        "id": "xLSuA8jLsRAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your data.yaml file\n",
        "data_yaml = \"/content/data/dataset.yaml\"\n",
        "# Train the model using configurations from config.yaml\n",
        "results = train_yolo(\n",
        "    data_yaml_path=str(data_yaml)\n",
        ")"
      ],
      "metadata": {
        "id": "Gita_NEEsmuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display training results\n",
        "print(\"Training completed!\")\n",
        "print(f\"Results saved to: {results.save_dir}\")"
      ],
      "metadata": {
        "id": "LBUoMQuGspFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps: Preperation / Quantization of the model for RB3Gen2\n",
        "I recommend the following be run on your personal machine but you can do this on the Colab too however the last step takes forever to complete."
      ],
      "metadata": {
        "id": "wRNV4mdSoXhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qai-hub-models[yolov8-det-quantized]"
      ],
      "metadata": {
        "id": "j7o6xmuDkyIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Account on AI Hub and get API Token.\n",
        "!qai-hub configure --api_token <YOUR_API_TOKEN>"
      ],
      "metadata": {
        "id": "0qe0HijnlFEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m qai_hub_models.models.yolov8_det_quantized.export --device=\"RB3 Gen 2 (Proxy)\" --ckpt-name /content/runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "clJsd7QymJj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RB3Gen2 Preperation / RB3Gen2 Commands\n"
      ],
      "metadata": {
        "id": "0VAykKdar521"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"PATH_TO_FILE_FROM_AIHUB\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get output tensor details\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "q_scales = []\n",
        "q_zero_points = []\n",
        "\n",
        "for output in output_details:\n",
        "    params = output['quantization_parameters']\n",
        "\n",
        "    # Check if the tensor is quantized\n",
        "    if output['quantization_parameters']['quantized_dimension'] == 0:  # Per-tensor quantization\n",
        "        scale = params['scales'][0] if params['scales'].size > 0 else 1.0\n",
        "        zero_point = params['zero_points'][0] if params['zero_points'].size > 0 else 0.0\n",
        "    else:\n",
        "        # Handle per-channel quantization (unlikely for YOLOv8)\n",
        "        scale = 1.0\n",
        "        zero_point = 0.0\n",
        "\n",
        "    q_scales.append(scale)\n",
        "    q_zero_points.append(float(zero_point))\n",
        "\n",
        "# Format the constants\n",
        "print(f'YOLOv8,q-offsets=<{\", \".join(map(str, q_zero_points))}>, q-scales=<{\", \".join(map(str, q_scales))}>')"
      ],
      "metadata": {
        "id": "P80_o_Q4slaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gst-launch-1.0 -e --gst-debug=2 \\\n",
        "qtiqmmfsrc name=camsrc ! video/x-raw\\(memory:GBM\\),format=NV12,width=1280,height=720,framerate=30/1,compression=ubwc ! queue ! tee name=split \\\n",
        "split. ! queue ! qtivcomposer name=mixer ! queue ! waylandsink fullscreen=true \\\n",
        "split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so \\\n",
        "external-delegate-options=\"QNNExternalDelegate,backend_type=htp;\" model=/opt/yolov8_det_quantized.tflite ! queue ! \\\n",
        "qtimlvdetection threshold=50.0 results=10 module=yolov8 labels=/opt/coco_labels.txt constants=\"YOLOv8,q-offsets=<21.0, 0.0, 0.0>,q-scales=<3.093529462814331, 0.00390625, 1.0>;\" ! \\\n",
        "video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.\n"
      ],
      "metadata": {
        "id": "wzc7bZxss4tC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}