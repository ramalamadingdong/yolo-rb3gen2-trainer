{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQwYDBNUixUv4m6X1/Rph8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramalamadingdong/yolo-rb3gen2-trainer/blob/main/Demo_YOLO_to_RB3Gen2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Retrain YOLOv8 on Synthetic Data"
      ],
      "metadata": {
        "id": "XGnEFcOLqF7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fjoMWTqBpPui",
        "outputId": "b24c7378-9658-4b66-972c-734881393c74",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolo-rb3gen2-trainer'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 14 (delta 0), reused 14 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (14/14), 125.14 KiB | 10.43 MiB/s, done.\n",
            "/content/yolo-rb3gen2-trainer\n",
            "Collecting qai_hub (from -r requirements.txt (line 1))\n",
            "  Downloading qai_hub-0.27.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting ultralytics (from -r requirements.txt (line 2))\n",
            "  Downloading ultralytics-8.3.107-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.21.0+cu124)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.13.2)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.6.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.3.56 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (4.11.0.86)\n",
            "Collecting backoff>=2.2 (from qai_hub->-r requirements.txt (line 1))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting deprecation (from qai_hub->-r requirements.txt (line 1))\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: h5py<4,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from qai_hub->-r requirements.txt (line 1)) (3.13.0)\n",
            "Collecting numpy>=1.19.5 (from -r requirements.txt (line 6))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from qai_hub->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: prettytable>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from qai_hub->-r requirements.txt (line 1)) (3.16.0)\n",
            "Collecting protobuf<4,>=3.20 (from qai_hub->-r requirements.txt (line 1))\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from qai_hub->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from qai_hub->-r requirements.txt (line 1)) (1.0.0)\n",
            "Collecting s3transfer<0.11,>=0.10.3 (from qai_hub->-r requirements.txt (line 1))\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting semver>=3.0 (from qai_hub->-r requirements.txt (line 1))\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from qai_hub->-r requirements.txt (line 1)) (4.13.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 2)) (1.14.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 2)) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 2))\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.7.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 9)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 9)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 9)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.2->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->-r requirements.txt (line 12)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->-r requirements.txt (line 12)) (3.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable>=3.9.0->qai_hub->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.2->-r requirements.txt (line 9)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->qai_hub->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->qai_hub->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->qai_hub->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->qai_hub->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Collecting botocore<2.0a.0,>=1.33.2 (from s3transfer<0.11,>=0.10.3->qai_hub->-r requirements.txt (line 1))\n",
            "  Downloading botocore-1.37.33-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 3)) (3.0.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<2.0a.0,>=1.33.2->s3transfer<0.11,>=0.10.3->qai_hub->-r requirements.txt (line 1))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Downloading qai_hub-0.27.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.107-py3-none-any.whl (974 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.5/974.5 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading botocore-1.37.33-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: semver, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, jmespath, deprecation, backoff, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, qai_hub, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-metadata 1.17.0 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 botocore-1.37.33 deprecation-2.1.0 jmespath-1.0.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-3.20.3 qai_hub-0.27.0 s3transfer-0.10.4 semver-3.0.4 ultralytics-8.3.107 ultralytics-thop-2.0.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "1823a6c2e00b41fd9191c9abbd7c5165"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/ramalamadingdong/yolo-rb3gen2-trainer\n",
        "%cd yolo-rb3gen2-trainer\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "8qAfKMBNq_Ao",
        "outputId": "07687987-3558-4f0c-d6aa-445d81e5a67f",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-541d390fcaae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The following functions are used to prepare data.\n",
        "\n",
        "def create_directories(output_dir):\n",
        "    \"\"\"Create necessary output directories.\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    train_dir = output_dir / 'train'\n",
        "    val_dir = output_dir / 'val'\n",
        "    for split in [train_dir, val_dir]:\n",
        "        (split / 'images').mkdir(parents=True, exist_ok=True)\n",
        "        (split / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "    return output_dir, train_dir, val_dir\n",
        "\n",
        "def add_training_picture(draw, image_size):\n",
        "    \"\"\"Place an training image with random position and rotation.\"\"\"\n",
        "\n",
        "    train_img_pth = random.choice(list(Path('/content/yolo-rb3gen2-trainer/training_images').glob('*.png')))\n",
        "    tag = Image.open(train_img_pth).convert('L')  # Convert to grayscale for better quality\n",
        "\n",
        "    # YOU MAY WANT TO CHANGE THIS FOR BETTER RESULTS\n",
        "    # Randomly resize tag between 40-120 pixels while maintaining aspect ratio\n",
        "    tag_w, tag_h = tag.size\n",
        "    target_size = random.randint(40, 120)\n",
        "    scale = min(target_size/tag_w, target_size/tag_h)\n",
        "    new_size = (int(tag_w * scale), int(tag_h * scale))\n",
        "\n",
        "    # Use nearest neighbor resampling to preserve sharp edges and binary nature of Training picture\n",
        "    tag = tag.resize(new_size, Image.NEAREST)\n",
        "\n",
        "    # Threshold to ensure pure black and white\n",
        "    tag = tag.point(lambda x: 0 if x < 128 else 255, '1')\n",
        "\n",
        "    # Get new dimensions after resize\n",
        "    width, height = tag.size\n",
        "\n",
        "    # Random position\n",
        "    x = random.randint(0, image_size[0] - width)\n",
        "    y = random.randint(0, image_size[1] - height)\n",
        "\n",
        "    # Random rotation angle\n",
        "    angle = random.uniform(0, 360)\n",
        "\n",
        "    # Apply rotation\n",
        "    tag = tag.rotate(angle, expand=False)\n",
        "\n",
        "    # Get rotated dimensions\n",
        "    rot_width, rot_height = tag.size\n",
        "\n",
        "    # Paste rotated tag onto image\n",
        "    draw._image.paste(tag, (x - (rot_width - width)//2, y - (rot_height - height)//2))\n",
        "\n",
        "    # Calculate corners of rotated rectangle\n",
        "    center_x = x + width/2\n",
        "    center_y = y + height/2\n",
        "\n",
        "    # Return corners for bounding box calculation\n",
        "    corners = [\n",
        "        (x, y),\n",
        "        (x + rot_width, y),\n",
        "        (x + rot_width, y + rot_height),\n",
        "        (x, y + rot_height)\n",
        "    ]\n",
        "    return corners\n",
        "\n",
        "def create_yolo_label(shape, class_id, image_size):\n",
        "    \"\"\"Convert shape coordinates to YOLO format.\"\"\"\n",
        "    x_coords = [p[0] for p in shape]\n",
        "    y_coords = [p[1] for p in shape]\n",
        "    x_center = (min(x_coords) + max(x_coords)) / (2 * image_size[0])\n",
        "    y_center = (min(y_coords) + max(y_coords)) / (2 * image_size[1])\n",
        "    width = (max(x_coords) - min(x_coords)) / image_size[0]\n",
        "    height = (max(y_coords) - min(y_coords)) / image_size[1]\n",
        "\n",
        "    return f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "def generate_dataset(output_dir, num_images, image_size):\n",
        "    \"\"\"Generate synthetic dataset with images and labels.\"\"\"\n",
        "    output_dir, train_dir, val_dir = create_directories(output_dir)\n",
        "    classes = ['AprilTag']\n",
        "\n",
        "    # Split into train and validation\n",
        "    train_size = int(0.8 * num_images)\n",
        "    val_size = num_images - train_size\n",
        "\n",
        "    for split, size in [('train', train_size), ('val', val_size)]:\n",
        "        print(f\"Generating {split} dataset...\")\n",
        "        for i in range(size):\n",
        "            # Load base image\n",
        "            image = Image.open('/content/yolo-rb3gen2-trainer/base_image.jpg').resize(image_size)\n",
        "            draw = ImageDraw.Draw(image)\n",
        "\n",
        "            # Generate random number of shapes\n",
        "            num_shapes = random.randint(1, 3)\n",
        "            labels = []\n",
        "\n",
        "            for _ in range(num_shapes):\n",
        "                skewed_corners = add_training_picture(draw, image_size)\n",
        "\n",
        "                # Calculate bounding box from skewed corners with padding\n",
        "                x_coords = [corner[0] for corner in skewed_corners]\n",
        "                y_coords = [corner[1] for corner in skewed_corners]\n",
        "\n",
        "                # Add 20% padding to bounding box\n",
        "                padding_x = (max(x_coords) - min(x_coords)) * 0.1\n",
        "                padding_y = (max(y_coords) - min(y_coords)) * 0.1\n",
        "\n",
        "                bbox = [\n",
        "                    (max(0, min(x_coords) - padding_x), max(0, min(y_coords) - padding_y)),\n",
        "                    (min(image_size[0], max(x_coords) + padding_x),\n",
        "                     min(image_size[1], max(y_coords) + padding_y))\n",
        "                ]\n",
        "\n",
        "                label = create_yolo_label(bbox, classes.index(\"AprilTag\"), image_size)\n",
        "                labels.append(label)\n",
        "\n",
        "            # Save image\n",
        "            image_path = output_dir / split / 'images' / f'image_{i:04d}.jpg'\n",
        "            image.save(image_path)\n",
        "\n",
        "            # Save label\n",
        "            label_path = output_dir / split / 'labels' / f'image_{i:04d}.txt'\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write('\\n'.join(labels))\n",
        "\n",
        "def create_dataset_yaml(output_dir):\n",
        "    \"\"\"Create YAML file for dataset configuration.\"\"\"\n",
        "    classes = ['AprilTag']\n",
        "    yaml_content = {\n",
        "        'path': str(output_dir),\n",
        "        'train': '/content/data/train/images',\n",
        "        'val': '/content/data/val/images',\n",
        "        'nc': len(classes),\n",
        "        'names': classes\n",
        "    }\n",
        "\n",
        "    with open(output_dir / 'dataset.yaml', 'w') as f:\n",
        "        yaml.dump(yaml_content, f, sort_keys=False)"
      ],
      "metadata": {
        "id": "7Nw3iab5rfr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The following functions are used to Train Yolo.\n",
        "\n",
        "def load_config(config_path: str = \"/content/yolo-rb3gen2-trainer/config.yaml\"):\n",
        "    \"\"\"\n",
        "    Load configuration from YAML file.\n",
        "\n",
        "    Args:\n",
        "        config_path (str): Path to the config.yaml file\n",
        "\n",
        "    Returns:\n",
        "        dict: Configuration dictionary\n",
        "    \"\"\"\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    return config\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory and garbage collection\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def train_yolo(\n",
        "    data_yaml_path: str,\n",
        "    config_path: str = \"/content/yolo-rb3gen2-trainer/config.yaml\",\n",
        "    **kwargs\n",
        "):\n",
        "    \"\"\"\n",
        "    Train a YOLOv8 model on a custom dataset using configurations from config.yaml.\n",
        "\n",
        "    Args:\n",
        "        data_yaml_path (str): Path to the data.yaml file containing dataset configuration\n",
        "        config_path (str): Path to the config.yaml file containing training configuration\n",
        "        **kwargs: Additional arguments to override config settings\n",
        "    \"\"\"\n",
        "    # Clear GPU memory before starting\n",
        "    clear_gpu_memory()\n",
        "\n",
        "    # Load configuration\n",
        "    config = load_config(config_path)\n",
        "\n",
        "    # Get model configuration\n",
        "    model_config = config['model']\n",
        "    model_type = f\"{model_config['type']}.pt\"\n",
        "\n",
        "    # Get training configuration\n",
        "    train_config = config['train']\n",
        "\n",
        "    # Update training config with any provided kwargs\n",
        "    train_config.update(kwargs)\n",
        "\n",
        "    # Force CPU device if CUDA is causing issues\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            # Print CUDA device information\n",
        "            print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "            print(f\"CUDA version: {torch.version.cuda}\")\n",
        "            print(f\"PyTorch version: {torch.__version__}\")\n",
        "            print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "\n",
        "            # Test CUDA compatibility with smaller batch size\n",
        "            test_model = YOLO(model_type)\n",
        "            test_model.to('cuda')\n",
        "            test_model.predict('https://ultralytics.com/images/bus.jpg', device='cuda', batch=1)\n",
        "\n",
        "            # Clear memory after test\n",
        "            clear_gpu_memory()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"CUDA compatibility issue detected: {str(e)}\")\n",
        "            print(\"Falling back to CPU.\")\n",
        "            train_config['device'] = 'cpu'\n",
        "    else:\n",
        "        print(\"CUDA is not available. Using CPU.\")\n",
        "        train_config['device'] = 'cpu'\n",
        "\n",
        "    # Initialize model\n",
        "    model = YOLO(model_type)\n",
        "\n",
        "    # Train the model with error handling\n",
        "    try:\n",
        "        results = model.train(\n",
        "            data=data_yaml_path,\n",
        "            epochs=train_config['epochs'],\n",
        "            batch=train_config['batch_size'],\n",
        "            imgsz=train_config['imgsz'],\n",
        "            device=train_config['device'],\n",
        "            project=train_config['project'],\n",
        "            name=train_config['name'],\n",
        "            exist_ok=train_config['exist_ok'],\n",
        "            pretrained=train_config['pretrained'],\n",
        "            optimizer=train_config['optimizer'],\n",
        "            verbose=train_config['verbose'],\n",
        "            seed=train_config['seed'],\n",
        "            deterministic=train_config['deterministic'],\n",
        "            single_cls=train_config['single_cls'],\n",
        "            rect=train_config['rect'],\n",
        "            cos_lr=train_config['cos_lr'],\n",
        "            close_mosaic=train_config['close_mosaic'],\n",
        "            resume=train_config['resume'],\n",
        "            amp=train_config['amp'],\n",
        "            fraction=train_config['fraction'],\n",
        "            nbs=train_config['nbs'],\n",
        "            overlap_mask=train_config['overlap_mask'],\n",
        "            mask_ratio=train_config['mask_ratio'],\n",
        "            dropout=train_config['dropout'],\n",
        "            val=train_config['val']\n",
        "        )\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training error occurred: {str(e)}\")\n",
        "        # Clear GPU memory after error\n",
        "        clear_gpu_memory()\n",
        "        raise e"
      ],
      "metadata": {
        "id": "nljhNibtr5V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "output_dir = 'data'\n",
        "num_images = 100\n",
        "image_size = (1280, 720)\n",
        "\n",
        "# Generate dataset\n",
        "generate_dataset(output_dir, num_images, image_size)\n",
        "\n",
        "# Create dataset YAML\n",
        "create_dataset_yaml(Path(output_dir))\n",
        "\n",
        "print(\"Dataset generation completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLSuA8jLsRAv",
        "outputId": "2d6c37d9-bf0e-4e8c-d8c1-e742bbc1cec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating train dataset...\n",
            "Generating val dataset...\n",
            "Dataset generation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your data.yaml file\n",
        "data_yaml = \"/content/data/dataset.yaml\"\n",
        "# Train the model using configurations from config.yaml\n",
        "results = train_yolo(\n",
        "    data_yaml_path=str(data_yaml)\n",
        ")"
      ],
      "metadata": {
        "id": "Gita_NEEsmuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display training results\n",
        "print(\"Training completed!\")\n",
        "print(f\"Results saved to: {results.save_dir}\")"
      ],
      "metadata": {
        "id": "LBUoMQuGspFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e146759-3cbb-4c2e-9a63-59495e29f589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed!\n",
            "Results saved to: runs/train/exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Steps: Preperation / Quantization of the model for RB3Gen2\n",
        "I recommend the following be run on your personal machine but you can do this on the Colab too however the last step takes forever to complete."
      ],
      "metadata": {
        "id": "wRNV4mdSoXhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qai-hub-models[yolov8-det-quantized]"
      ],
      "metadata": {
        "id": "j7o6xmuDkyIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Account on AI Hub and get API Token.\n",
        "!qai-hub configure --api_token <YOUR_API_TOKEN>"
      ],
      "metadata": {
        "id": "0qe0HijnlFEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m qai_hub_models.models.yolov8_det_quantized.export --device=\"RB3 Gen 2 (Proxy)\" --ckpt-name /content/runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "clJsd7QymJj3",
        "outputId": "830f8f91-1f8d-4cbc-fd7e-2482caad89a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/qai_hub_models/utils/quantization.py:132: UserWarning: \n",
            "\n",
            "!!! WARNING !!!\n",
            "Quantized model package yolov8_det_quantized is deprecated. Use the equivalent unquantized model package (yolov8_det) instead.\n",
            "You can use qai_hub_models.models.yolov8_det.export and qai_hub_models.models.yolov8_det.evaluate with the `--precision w8a8` flag to replicate previous behavior of those scripts.\n",
            "\n",
            "\n",
            "  warnings.warn(\n",
            "Quantizing model yolov8_det.\n",
            "Uploading tmpc20gd6g1.pt\n",
            "100% 12.1M/12.1M [00:02<00:00, 5.89MB/s]\n",
            "Scheduled compile job (jp1y2x22p) successfully. To see the status and results:\n",
            "    https://app.aihub.qualcomm.com/jobs/jp1y2x22p/\n",
            "\n",
            "Downloading data\n",
            "Downloading split 'train' to '/root/.qaihm/fiftyone/coco-2017/train' if necessary\n",
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/.qaihm/fiftyone/coco-2017/train' if necessary\n",
            "Found annotations at '/root/.qaihm/fiftyone/coco-2017/raw/instances_train2017.json'\n",
            "INFO:fiftyone.utils.coco:Found annotations at '/root/.qaihm/fiftyone/coco-2017/raw/instances_train2017.json'\n",
            "642 images found; downloading the remaining 4358\n",
            "INFO:fiftyone.utils.coco:642 images found; downloading the remaining 4358\n",
            "\n",
            "INFO:eta.core.utils:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 856, in next\n",
            "    item = self._items.popleft()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/utils/coco.py\", line 1928, in _download_images\n",
            "    for _ in pool.imap_unordered(_do_download, tasks):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 861, in next\n",
            "    self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 327, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/models/yolov8_det_quantized/export.py\", line 14, in <module>\n",
            "    main(Precision.w8a8)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/models/yolov8_det/export.py\", line 292, in main\n",
            "    export_model(**vars(args))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/models/yolov8_det/export.py\", line 157, in export_model\n",
            "    calibration_data = quantization_utils.get_calibration_data(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/utils/quantization.py\", line 111, in get_calibration_data\n",
            "    dataset = get_dataset_from_name(calibration_dataset_name, split=DatasetSplit.TRAIN)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/datasets/__init__.py\", line 82, in get_dataset_from_name\n",
            "    return dataset_cls(split=split)  # type: ignore[call-arg]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/datasets/coco.py\", line 85, in __init__\n",
            "    BaseDataset.__init__(self, \"non_existent_dir\", split)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/datasets/common.py\", line 42, in __init__\n",
            "    self.download_data()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/datasets/common.py\", line 56, in download_data\n",
            "    self._download_data()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/qai_hub_models/datasets/coco.py\", line 182, in _download_data\n",
            "    self.dataset = foz.load_zoo_dataset(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/zoo/datasets/__init__.py\", line 335, in load_zoo_dataset\n",
            "    info, dataset_dir = download_zoo_dataset(\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/zoo/datasets/__init__.py\", line 215, in download_zoo_dataset\n",
            "    info = zoo_dataset.download_and_prepare(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/zoo/datasets/__init__.py\", line 1306, in download_and_prepare\n",
            "    ) = self._download_and_prepare(split_dir, scratch_dir, split)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/zoo/datasets/base.py\", line 1145, in _download_and_prepare\n",
            "    num_samples, classes, downloaded = fouc.download_coco_dataset_split(\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/utils/coco.py\", line 1748, in download_coco_dataset_split\n",
            "    _download_images(images_dir, download_ids, images, num_workers)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fiftyone/utils/coco.py\", line 1927, in _download_images\n",
            "    with multiprocessing.dummy.Pool(num_workers) as pool:\n",
            "  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 739, in __exit__\n",
            "    self.terminate()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 657, in terminate\n",
            "    self._terminate()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 227, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/pool.py\", line 709, in _terminate_pool\n",
            "    worker_handler.join()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RB3Gen2 Preperation / RB3Gen2 Commands\n"
      ],
      "metadata": {
        "id": "0VAykKdar521"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"PATH_TO_FILE_FROM_AIHUB\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get output tensor details\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "q_scales = []\n",
        "q_zero_points = []\n",
        "\n",
        "for output in output_details:\n",
        "    params = output['quantization_parameters']\n",
        "\n",
        "    # Check if the tensor is quantized\n",
        "    if output['quantization_parameters']['quantized_dimension'] == 0:  # Per-tensor quantization\n",
        "        scale = params['scales'][0] if params['scales'].size > 0 else 1.0\n",
        "        zero_point = params['zero_points'][0] if params['zero_points'].size > 0 else 0.0\n",
        "    else:\n",
        "        # Handle per-channel quantization (unlikely for YOLOv8)\n",
        "        scale = 1.0\n",
        "        zero_point = 0.0\n",
        "\n",
        "    q_scales.append(scale)\n",
        "    q_zero_points.append(float(zero_point))\n",
        "\n",
        "# Format the constants\n",
        "print(f'YOLOv8,q-offsets=<{\", \".join(map(str, q_zero_points))}>, q-scales=<{\", \".join(map(str, q_scales))}>')"
      ],
      "metadata": {
        "id": "P80_o_Q4slaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bbf5e0c-de2f-45cd-ff4c-ec47eb84fb8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8,q-offsets=<36.0, 0.0, 0.0>, q-scales=<3.9993956, 0.003825209, 1.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gst-launch-1.0 -e --gst-debug=2 \\\n",
        "qtiqmmfsrc name=camsrc ! video/x-raw\\(memory:GBM\\),format=NV12,width=1280,height=720,framerate=30/1,compression=ubwc ! queue ! tee name=split \\\n",
        "split. ! queue ! qtivcomposer name=mixer ! queue ! waylandsink fullscreen=true \\\n",
        "split. ! queue ! qtimlvconverter ! queue ! qtimltflite delegate=external external-delegate-path=libQnnTFLiteDelegate.so \\\n",
        "external-delegate-options=\"QNNExternalDelegate,backend_type=htp;\" model=/opt/yolov8_det_quantized.tflite ! queue ! \\\n",
        "qtimlvdetection threshold=50.0 results=10 module=yolov8 labels=/opt/coco_labels.txt constants=\"YOLOv8,q-offsets=<21.0, 0.0, 0.0>,q-scales=<3.093529462814331, 0.00390625, 1.0>;\" ! \\\n",
        "video/x-raw,format=BGRA,width=640,height=360 ! queue ! mixer.\n"
      ],
      "metadata": {
        "id": "wzc7bZxss4tC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c62179-457b-42ed-8e6f-8db0ebcb686e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: gst-launch-1.0: command not found\n"
          ]
        }
      ]
    }
  ]
}